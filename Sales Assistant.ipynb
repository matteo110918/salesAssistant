{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"border: 1px solid #ccc; padding: 10px; border-radius: 5px;\">\n",
    "    <table style=\"width: 100%;\">\n",
    "        <tr>\n",
    "            <td style=\"width: 10%; text-align: center; vertical-align: top;\">\n",
    "                <img src=\"./images/robotic_sales_assistent.PNG\" alt=\"Robotic Sales Assistent\" width=\"200\">\n",
    "            </td>\n",
    "            <td style=\"width: 70%; vertical-align: top; padding-left: 15px;\">\n",
    "                <h3>Use Case: Sales Assistent</h3>\n",
    "                <p>\n",
    "                    The Sales Assistant is a tool designed to streamline the preparation process for sales professionals by generating compact, data-driven company presentations based on publicly available information from corporate websites. Users provide the company name and URL, and the system scrapes and analyzes relevant web pages such as \"About Us\" or \"Careers,\" extracting key insights about company culture, offerings, and career opportunities. Leveraging AI for content generation, it outputs a concise, Markdown-formatted brochure that can be used directly in client meetings or internal planning. This solution saves time, enhances the quality of sales interactions, and ensures that representatives are well-prepared with up-to-date and relevant information.\n",
    "                </p>\n",
    "            </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n"
   ],
   "id": "b9dede75d5ed8391"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ],
   "id": "56ef8634c5c3ffa8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize and constants\n",
    "\n",
    "# Load the .env file containing environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Validate API key format\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "\n",
    "# Set the AI model to be used    \n",
    "MODEL = 'gpt-4o-mini'\n",
    "\n",
    "# Initialize OpenAI API client\n",
    "openai = OpenAI()"
   ],
   "id": "5ee367c6fb4155e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "        A utility class to represent a Website for scraping content and extracting links.\n",
    "    \n",
    "        Attributes:\n",
    "            url (str): The URL of the website.\n",
    "            body (str): The raw HTML content of the webpage.\n",
    "            title (str): The title of the webpage, if available.\n",
    "            text (str): The cleaned text content of the webpage.\n",
    "            links (list): A list of hyperlinks (absolute and relative) found on the webpage.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url: str):\n",
    "        \"\"\"\n",
    "        Initialize the Website class by fetching the webpage content.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL of the webpage to scrape.\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        self.body = response.content\n",
    "        \n",
    "        # Parse HTML content with BeautifulSoup\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        \n",
    "        # Extract the title of the page\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        \n",
    "        # Remove irrelevant elements like scripts, styles, and images\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        \n",
    "        # Extract all hyperlinks on the page\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self) -> str:\n",
    "        \"\"\"\n",
    "        Retrieve the cleaned text content of the webpage.\n",
    "\n",
    "        Returns:\n",
    "            str: A string containing the webpage title and content.\n",
    "        \"\"\"\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ],
   "id": "7d7717f9f29d23d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## First step: Have GPT-4o-mini figure out which links are relevant\n",
    "\n",
    "### Use a call to gpt-4o-mini to read the links on a webpage, and respond in structured JSON.  \n",
    "It should decide which links are relevant, and replace relative links such as \"/about\" with \"https://company.com/about\".  \n",
    "I will use \"one shot prompting\" in which we provide an example of how it should respond in the prompt."
   ],
   "id": "99552daa2ba2136e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the system prompt for filtering links\n",
    "\n",
    "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
    "link_system_prompt += \"You should respond in JSON as in this example:\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ],
   "id": "a042ded72b165000",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the user prompt for filtering links\n",
    "\n",
    "def get_links_user_prompt(website) -> str:\n",
    "    \"\"\"\n",
    "    Create a user prompt for analyzing links found on a website.\n",
    "\n",
    "    Args:\n",
    "        website (Website): The Website object containing link data.\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted prompt to be sent to the AI model.\n",
    "    \"\"\"\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt"
   ],
   "id": "35ce9d43d1df8e1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ask the AI model for the most relevant links and return as JSON\n",
    "\n",
    "def get_links(url: str) -> dict:\n",
    "    \"\"\"\n",
    "    Identify the most relevant links from a webpage.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the webpage to analyze.\n",
    "\n",
    "    Returns:\n",
    "        dict: A JSON object containing the filtered links and their types.\n",
    "    \"\"\"\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "      ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    return json.loads(result)"
   ],
   "id": "1db3093ec8f396c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Second step: make the brochure!\n",
    "\n",
    "Assemble all the details into another prompt to GPT4-o"
   ],
   "id": "f7743d21e3b80854"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Crawl information from relevant links\n",
    "\n",
    "def get_all_details(url:str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve and aggregate content from the landing page and its relevant links.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the company's webpage.\n",
    "\n",
    "    Returns:\n",
    "        str: A string containing the aggregated content from all relevant pages.\n",
    "    \"\"\"\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()\n",
    "    links = get_links(url)\n",
    "    print(\"Found links:\", links)\n",
    "    for link in links[\"links\"]:\n",
    "        result += f\"\\n\\n{link['type']}\\n\"\n",
    "        result += Website(link[\"url\"]).get_contents()\n",
    "    return result"
   ],
   "id": "e62d8945a059042b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# System prompt for brochure creation\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\""
   ],
   "id": "3440447b8416f491",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create user prompt for generating the brochure\n",
    "\n",
    "def get_brochure_user_prompt(company_name: str, url: str) -> str:\n",
    "    \"\"\"\n",
    "    Create a user prompt for generating a company brochure.\n",
    "\n",
    "    Args:\n",
    "        company_name (str): The name of the company.\n",
    "        url (str): The URL of the company's website.\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted user prompt for the AI model.\n",
    "    \"\"\"\n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url)\n",
    "    user_prompt = user_prompt[:20_000] # Truncate if more than 20,000 characters\n",
    "    return user_prompt"
   ],
   "id": "7be111646acc3775",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Generate the brochure\n",
    "\n",
    "def create_brochure(company_name: str, url: str):\n",
    "    \"\"\"\n",
    "    Generate a company brochure using AI.\n",
    "\n",
    "    Args:\n",
    "        company_name (str): The name of the company.\n",
    "        url (str): The URL of the company's website.\n",
    "    \"\"\"       \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "      ]\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    # Yield each chunk of the streaming response\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ],
   "id": "c8ebafa95515481a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example usage:\n",
    "create_brochure('Durst Group AG', 'https://www.durst-group.com')"
   ],
   "id": "303cb95f21f31a0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Gradio Interface with layout adjustments\n",
    "with gr.Blocks() as interface:\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):  # Input section takes 1/3 of the width\n",
    "            company_name = gr.Textbox(label=\"Company Name:\", placeholder=\"Enter the company name\")\n",
    "            url = gr.Textbox(label=\"Company Website URL:\", placeholder=\"Enter company URL with http or https\")\n",
    "            generate_button = gr.Button(\"Generate Brochure\")\n",
    "        with gr.Column(scale=2):  # Output section takes 2/3 of the width\n",
    "            output = gr.Markdown(label=\"Generated Company Brochure\")\n",
    "\n",
    "    # Link button click to the function\n",
    "    generate_button.click(\n",
    "        fn=create_brochure,  # The function to call\n",
    "        inputs=[company_name, url],  # Inputs to pass to the function\n",
    "        outputs=output  # Output to update with the result\n",
    "    )\n",
    "\n",
    "# Launch the Gradio Interface\n",
    "interface.launch()"
   ],
   "id": "677240e686e73672",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
